> 论文标题：A Case Study on Sampling Strategies for Evaluating Neural Sequential Item Recommendation Models
>
> 发表于：2021  RecSys
>
> 作者：Alexander Dallmann，Daniel Zoller，Andreas Hotho
>
> 代码：
>
> 论文地址：https://arxiv.org/pdf/2107.13045.pdf

## 摘要

- 顺序项目推荐模型是通过在小项目子集（目标集）上计算度量来比较的，以加快计算速度
- 目标集包含相关项目和从完整项目集中采样的一组负样本项目
- 两种负采样的策略是 均匀随机抽样 和 按流行度抽样 ，以更好地近似数据集中的项目频率分布。
- 最近的工作表明，采用均匀随机抽样的评估可能与全排名不一致，
  - 全排名：即以全项目集为目标集评估一个指标得到的模型排名，
  - 这就提出了通过流行度抽样获得的排名是否等于完整排名的问题
- 文章中从这些采样策略是否对模型的最终排名产生影响的角度重新评估了当前最先进的顺序推荐模型
  - 对于每个数据集和模型，采用三种评估策略
    - 首先，计算完整的模型排名
    - 然后，评估通过两种不同采样策略（均匀随机采样和流行度采样）采样的目标集上的所有模型，计算每个策略的模型排名并相互比较
      - 常用的目标集大小为 100，
    - 改变了采样目标集的大小
- 实验发现与模型的完整排名相比，两种抽样策略都会产生不一致的排名。当在不同样本量上进行比较时，流行度抽样和均匀随机抽样始终都不会产生相同的排名
- 与均匀随机抽样一样，通过流行度抽样获得的排名并不等于推荐模型的完整排名，因此在建立最先进的技术时，应避免两者都支持完整排名

## 结论

- 关注通过对小项目集的抽样与对完整项目集的评估不一致的评估的影响
- [5] 研究了使用完整项目集获得的排名与主要在协同过滤模型上通过均匀随机抽样获得的排名之间的不一致
- 将按流行度抽样作为研究中的第二种抽样策略，发现虽然它直观地更好地近似数据集中的项目分布，但它并没有提高与获得的排名的一致性完整的项目集
- 研究了最近的神经项目推荐模型，这些模型可以对项目序列中的复杂交互进行建模，但这些模型在使用抽样进行评估时也会受到排名不一致的影响
- 结论：
  - 独立于数据集、抽样类型或负样本项目数量的选择，抽样评估可能无法近似通过正确考虑完整项目集获得的排名
  - 在比较不同顺序推荐模型的性能时，这是一个糟糕的选择，并且无法避免在整个项目集上计算指标。

## 未来工作

- 将研究扩展到更多模型，以便更好地了解利用完整排名的性能差异
- 可以使用不同类型的数据集扩展研究。文章只使用了根据用户评论或评分构建的数据集，但存在其他类型的项目序列数据集
  - 例如，在线商店中的用户点击，并且可能表现出不同的特征
- 可以研究 Krichene 和 Rendle [25] 引入的现有稳健指标对本文评估模型和不同类型数据集的有效性。

## 介绍

- 开发推荐系统的一个关键部分是在此过程中对模型候选者的评估
- 在线评估是评估推荐模型的最佳选择 [28]，但它不适用于新模型的开发（例如，用于寻找最佳超参数设置）。
- 离线评估仍然是推荐在开发过程中评估新模型的最佳选择
- 现有工作通过采样评估加快度量计算的过程，而不是在整个项目集上计算指标以获得模型的排名（称为完整排名）
-  [25] 中表明，基于统一采样的推荐器评估的大多数使用指标的期望值取决于被评估模型分配的相关项目的等级
  - 因此抽样目标集上的排名可能与完整项目集上的排名不同。
- 文章使用三种不同的评估策略（1）完整项目集、（2）流行度抽样和（3）均匀随机抽样获得的模型性能排名进行了比较评估
- 通过抽样获得的两个排名都与文章测试的所有数据集上的完整排名不一致，
- 当改变数据集上的目标集大小时，抽样排名与完整排名不一致
- 在比较模型性能时应使用完整排名

## 实验

- ### 数据集

  - MovieLens-1m、MovieLens-20m
  - Amazon Beauty、Amazon Games
  - Steam

- ### baseline

  - GRU 
  - NARM [27]：带注意力的 RNN
  - SASRec 
  - BERT4Rec

- ### 超参数设置

- ### 评估指标

  - HR@K
  - NDCG@K