```python
import torch

x = torch.arange(12)  #生成0-12的张量

x.shape #张量的长度   output ：torch.size([12])
x.numel()  #元素的总数   output: 12

X = x.reshape(3,4)   #改变张良的形状而不改变元素数量和元素值 output: tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]])

#使用全0，全1，其他敞亮或者从特定分布中随机采样的数字
torch.zeros((2,3,4))  #全0
torch.ones((2,3,4)) #全1

torch.tensor([[2,1,4,3],[1,2,3,4]])  #通过python列表来为张量中每个元素赋值

torch.exp(x)  #指数运算 

#把多个张量连结在一起
X = torch.arange(12,dtype=torch.float32).reshape((3,4))
Y = torch.tensor([[2.0,1,4,3],[1,2,3,4],[4,3,2,1]])
torch.cat((X,Y), dim = 0),torch.cat((X,Y),dim = 1) #在第0维(行),第1维(列)合并
'''
output:tensor([[0.,1.,2.,3.,2.,1.,4.,3.],
			  [4.,5.,6.,7.,1.,2.,3.,4.],
			  [8.,9.,10.,11.,4.,3.,2.,1.]
'''

#即使形状不同，仍能通过调用广播机制来执行按元素操作
a = torch.arrange(3).reshape((3,1))   #output:[[0],[1],[2]]
b = torch.arrange(2).reshape((1,2))   #output:[[0,1]]
a+b   #output：tensor([[0,1],[1,2],[2,3]])

#运行一些操作可能会导致为新结果分配内存
before = id(Y)
Y = Y + X
id(Y) == before
#执行原地操作
Z = torch.zeros_like(Y)
Z[:] = X + Y
```

reshape 和 view 的区别

```
reshape为拷贝，修改之后原被reshape的tensor也会被修改
```

快速区分维度 ：a.shape
