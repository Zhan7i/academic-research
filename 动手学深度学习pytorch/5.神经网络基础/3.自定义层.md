## 自定义层

- ### 不带参数的层

  - ```python
    import torch
    import torch.nn.functional as F
    from torch import nn
    
    class CenteredLayer(nn.Module):
        def __init__(self):
            super().__init__()
    
        def forward(self, X):
            return X - X.mean()
        
    layer = CenteredLayer()
    layer(torch.FloatTensor([1, 2, 3, 4, 5]))
    # output：tensor([-2., -1.,  0.,  1.,  2.])
    ```

  - 将层作为组件合并到更复杂的模型中

    - ```python
      net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())
      Y = net(torch.rand(4, 8))
      Y.mean()  # output:tensor(-2.7940e-09, grad_fn=<MeanBackward0>)
      ```

- ### 带参数的图层

  - 输入参数：`in_units`和`units`，分别表示输入数和输出数

    - ```python
      class MyLinear(nn.Module):
          def __init__(self, in_units, units):
              super().__init__()
              self.weight = nn.Parameter(torch.randn(in_units, units))
              self.bias = nn.Parameter(torch.randn(units,))
          def forward(self, X):
              linear = torch.matmul(X, self.weight.data) + self.bias.data
              return F.relu(linear)
              
      linear = MyLinear(5, 3)
      linear.weight
      ''' output:
      Parameter containing:
      tensor([[-2.2981, -1.8825, -0.9347],
              [ 0.1222, -1.0374,  1.1512],
              [-0.2859, -0.0680,  0.9072],
              [ 1.2177, -0.8947,  0.6278],
              [ 1.4800,  0.5804, -0.9661]], requires_grad=True)
      '''
      # 使用自定义层直接执行前向传播计算
      linear(torch.rand(2, 5)) # output:tensor([[0.5392, 0.0000, 0.0000],[0.0000, 0.0000, 0.0000]])
      
      # 还可以使用自定义层构建模型，就像使用内置的全连接层一样使用自定义层
      net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))
      net(torch.rand(2, 64))  # output: tensor([[ 7.3940], [12.1799]])
      ```