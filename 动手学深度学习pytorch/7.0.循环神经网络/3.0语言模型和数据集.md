## 语言模型

- 给定文本序列$x_1,..,x_T$，语言模型的目标是估计联合概率$p(x_1,...,x_T)$
- 它的应用包括
  - 做预训练模型（如BERT,GPT-3）
  - 生成文本，给定前几个词，不断地使用  $x_t$~ $p (x_t|x_{t-τ},...,x_{t-1})$来生成后续文本
  - 判断多个序列中哪个更常见，如 "to recognize a nice speech" vs "to wreck a nice beach"

## 使用计数来建模

- 假设序列长度为2，我们预测$\large p(x,x') = p(x)p(x'|x) = \frac{n(x)}{n} \frac{n(x,x')}{n(x)}$
  - 这里n是总词数，n(x),n(x,x')是单个单词和连续单词对的出现词数
- 很容易拓展到长为3的情况
  - $\large p(x,x',x'') = p(x)p(x'|x)p(x''|x,x')= \frac{n(x)}{n} \frac{n(x,x')}{n(x)} \frac{n(x,x',x'')}{n(x,x')}$

## N元语法

- 当序列很长时，因为文本量不够大，很可能$n(x_1,...,x_T)≤1$
- 使用马尔科夫假设缓解这个问题
- $\begin{split}\begin{aligned}
  一元语法(\tau = 0)：P(x_1, x_2, x_3, x_4) &=  P(x_1) P(x_2) P(x_3) P(x_4),\\
  二元语法(\tau = 1)：P(x_1, x_2, x_3, x_4) &=  P(x_1) P(x_2  \mid  x_1) P(x_3  \mid  x_2) P(x_4  \mid  x_3),\\
  三元语法(\tau = 2)：P(x_1, x_2, x_3, x_4) &=  P(x_1) P(x_2  \mid  x_1) P(x_3  \mid  x_1, x_2) P(x_4  \mid  x_2, x_3).\\
  ...\end{aligned}\end{split}$

## 总结

- 语言模型估计文本序列的联合概率
- 使用统计方法是常采用n元语法